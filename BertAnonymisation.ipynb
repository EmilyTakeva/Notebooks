{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, you will find a method to anonymise a sample of text, where we concentrate our attention on the case of anonymising names in articles. The languages permited are as follows: Arabic, German, English, Spanish, French, Italian, Latvian, Dutch, Portuguese and Chinese."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers.pipelines.token_classification import TokenClassificationPipeline\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'entity_group': 'PER', 'score': 0.9998803, 'word': 'Emily', 'start': 0, 'end': 5}, {'entity_group': 'ORG', 'score': 0.9998514, 'word': 'BBC Studios', 'start': 15, 'end': 26}, {'entity_group': 'LOC', 'score': 0.9998155, 'word': 'London', 'start': 30, 'end': 36}]\n"
     ]
    }
   ],
   "source": [
    "# Let's try some Hugging face models for tokenising and classifying text\n",
    "\n",
    "model_checkpoint = \"Davlan/bert-base-multilingual-cased-ner-hrl\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_checkpoint)\n",
    "\n",
    "pipe = TokenClassificationPipeline(model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\", stride=10)\n",
    "ents = pipe(\"Emily works at BBC Studios in London.\")\n",
    "print(ents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to extend the model to handle longer than the initial caracters allowed, aka articles\n",
    "\n",
    "def preprocess(self, sentence, offset_mapping=None):\n",
    "        model_inputs = self.tokenizer(\n",
    "            sentence,\n",
    "            return_tensors=\"pt\",\n",
    "            truncation=True,\n",
    "            return_special_tokens_mask=True,\n",
    "            return_offsets_mapping=True,\n",
    "            return_overflowing_tokens=True,  # Return multiple chunks\n",
    "            max_length=self.tokenizer.model_max_length,\n",
    "            padding=True\n",
    "        )\n",
    "        if offset_mapping:\n",
    "            model_inputs[\"offset_mapping\"] = offset_mapping\n",
    "\n",
    "        model_inputs[\"sentence\"] = sentence\n",
    "\n",
    "        return model_inputs\n",
    "\n",
    "def _forward(self, model_inputs):\n",
    "        special_tokens_mask = model_inputs.pop(\"special_tokens_mask\")\n",
    "        offset_mapping = model_inputs.pop(\"offset_mapping\", None)\n",
    "        sentence = model_inputs.pop(\"sentence\")\n",
    "        overflow_to_sample_mapping = model_inputs.pop(\"overflow_to_sample_mapping\")\n",
    "\n",
    "        all_logits = torch.Tensor()\n",
    "        num_chunks = len(model_inputs[\"input_ids\"])\n",
    "\n",
    "        # Pass one chunk at a time to the model and concatenate the results\n",
    "        for i in range(num_chunks):\n",
    "            model_input = {k: torch.unsqueeze(v[i], dim=0) for k, v in model_inputs.items()}\n",
    "            logits = model(**model_input)[0]\n",
    "            all_logits = torch.cat((all_logits, logits), dim=1)\n",
    "\n",
    "        model_outputs = {\n",
    "            \"logits\": all_logits,\n",
    "            \"special_tokens_mask\": special_tokens_mask,\n",
    "            \"offset_mapping\": offset_mapping,\n",
    "            \"sentence\": sentence,\n",
    "            \"overflow_to_sample_mapping\": overflow_to_sample_mapping,\n",
    "            **model_inputs,\n",
    "        }\n",
    "\n",
    "        # We reshape outputs to fit with the postprocess inputs\n",
    "        model_outputs[\"input_ids\"] = torch.reshape(model_outputs[\"input_ids\"], (1, -1))\n",
    "        model_outputs[\"token_type_ids\"] = torch.reshape(model_outputs[\"token_type_ids\"], (1, -1))\n",
    "        model_outputs[\"attention_mask\"] = torch.reshape(model_outputs[\"attention_mask\"], (1, -1))\n",
    "        model_outputs[\"special_tokens_mask\"] = torch.reshape(model_outputs[\"special_tokens_mask\"], (1, -1))\n",
    "        model_outputs[\"offset_mapping\"] = torch.reshape(model_outputs[\"offset_mapping\"], (1, -1, 2))\n",
    "\n",
    "        return model_outputs\n",
    "\n",
    "class TokenClassificationChunkPipeline(TokenClassificationPipeline):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def preprocess(self, sentence, offset_mapping=None):\n",
    "        model_inputs = self.tokenizer(\n",
    "            sentence,\n",
    "            return_tensors=\"pt\",\n",
    "            truncation=True,\n",
    "            return_special_tokens_mask=True,\n",
    "            return_offsets_mapping=True,\n",
    "            return_overflowing_tokens=True,  # Return multiple chunks\n",
    "            max_length=self.tokenizer.model_max_length,\n",
    "            padding=True\n",
    "        )\n",
    "        if offset_mapping:\n",
    "            model_inputs[\"offset_mapping\"] = offset_mapping\n",
    "\n",
    "        model_inputs[\"sentence\"] = sentence\n",
    "\n",
    "        return model_inputs\n",
    "\n",
    "    def _forward(self, model_inputs):\n",
    "        special_tokens_mask = model_inputs.pop(\"special_tokens_mask\")\n",
    "        offset_mapping = model_inputs.pop(\"offset_mapping\", None)\n",
    "        sentence = model_inputs.pop(\"sentence\")\n",
    "        overflow_to_sample_mapping = model_inputs.pop(\"overflow_to_sample_mapping\")\n",
    "\n",
    "        all_logits = torch.Tensor()\n",
    "        num_chunks = len(model_inputs[\"input_ids\"])\n",
    "\n",
    "        # Pass one chunk at a time to the model and concatenate the results\n",
    "        for i in range(num_chunks):\n",
    "            model_input = {k: torch.unsqueeze(v[i], dim=0) for k, v in model_inputs.items()}\n",
    "            logits = model(**model_input)[0]\n",
    "            all_logits = torch.cat((all_logits, logits), dim=1)\n",
    "\n",
    "        model_outputs = {\n",
    "            \"logits\": all_logits,\n",
    "            \"special_tokens_mask\": special_tokens_mask,\n",
    "            \"offset_mapping\": offset_mapping,\n",
    "            \"sentence\": sentence,\n",
    "            \"overflow_to_sample_mapping\": overflow_to_sample_mapping,\n",
    "            **model_inputs,\n",
    "        }\n",
    "\n",
    "        # We reshape outputs to fit with the postprocess inputs\n",
    "        model_outputs[\"input_ids\"] = torch.reshape(model_outputs[\"input_ids\"], (1, -1))\n",
    "        model_outputs[\"token_type_ids\"] = torch.reshape(model_outputs[\"token_type_ids\"], (1, -1))\n",
    "        model_outputs[\"attention_mask\"] = torch.reshape(model_outputs[\"attention_mask\"], (1, -1))\n",
    "        model_outputs[\"special_tokens_mask\"] = torch.reshape(model_outputs[\"special_tokens_mask\"], (1, -1))\n",
    "        model_outputs[\"offset_mapping\"] = torch.reshape(model_outputs[\"offset_mapping\"], (1, -1, 2))\n",
    "\n",
    "        return model_outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'entity_group': 'ORG', 'score': 0.99182165, 'word': 'Essex Police', 'start': 78, 'end': 90}, {'entity_group': 'PER', 'score': 0.9101589, 'word': 'Teddy Bear', 'start': 120, 'end': 130}, {'entity_group': 'LOC', 'score': 0.99896306, 'word': 'St Osyth', 'start': 175, 'end': 183}, {'entity_group': 'LOC', 'score': 0.99515325, 'word': 'Clacton - on - Sea', 'start': 190, 'end': 204}, {'entity_group': 'PER', 'score': 0.99063396, 'word': 'Ginny Murphy', 'start': 242, 'end': 254}, {'entity_group': 'PER', 'score': 0.9322479, 'word': 'Teddy Bear', 'start': 400, 'end': 410}, {'entity_group': 'LOC', 'score': 0.99765104, 'word': 'Earl Hall Drive', 'start': 604, 'end': 619}, {'entity_group': 'ORG', 'score': 0.5572479, 'word': 'Col', 'start': 634, 'end': 637}, {'entity_group': 'LOC', 'score': 0.64672744, 'word': '##chester Zoo', 'start': 637, 'end': 648}, {'entity_group': 'PER', 'score': 0.9957657, 'word': 'Murphy', 'start': 855, 'end': 861}, {'entity_group': 'LOC', 'score': 0.997252, 'word': 'St Osyth', 'start': 866, 'end': 874}, {'entity_group': 'ORG', 'score': 0.72716385, 'word': 'Maine Co', 'start': 958, 'end': 966}, {'entity_group': 'PER', 'score': 0.9995042, 'word': 'Gill', 'start': 1129, 'end': 1133}, {'entity_group': 'PER', 'score': 0.9994316, 'word': 'Steve Atkin', 'start': 1138, 'end': 1149}, {'entity_group': 'LOC', 'score': 0.9994982, 'word': 'Louth', 'start': 1154, 'end': 1159}, {'entity_group': 'LOC', 'score': 0.99966764, 'word': 'Lincolnshire', 'start': 1161, 'end': 1173}, {'entity_group': 'PER', 'score': 0.99950767, 'word': 'Atkin', 'start': 1235, 'end': 1240}, {'entity_group': 'ORG', 'score': 0.9997924, 'word': 'BBC', 'start': 1472, 'end': 1475}, {'entity_group': 'PER', 'score': 0.9950885, 'word': 'Atkin', 'start': 1492, 'end': 1497}, {'entity_group': 'ORG', 'score': 0.91780436, 'word': 'The Mirror', 'start': 1504, 'end': 1514}, {'entity_group': 'PER', 'score': 0.9995839, 'word': 'Tom', 'start': 1600, 'end': 1603}, {'entity_group': 'PER', 'score': 0.99955505, 'word': 'Bob Martin', 'start': 1753, 'end': 1763}, {'entity_group': 'PER', 'score': 0.99961203, 'word': 'Denise', 'start': 1790, 'end': 1796}, {'entity_group': 'ORG', 'score': 0.9860487, 'word': 'Essex Police', 'start': 1971, 'end': 1983}, {'entity_group': 'LOC', 'score': 0.98392993, 'word': 'Colchester Zoo', 'start': 2171, 'end': 2185}]\n"
     ]
    }
   ],
   "source": [
    "  # Checking extension\n",
    "\n",
    "pipe = TokenClassificationPipeline(model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\", stride=10)\n",
    "ents = pipe(\"A woman has claimed sightings of a lion- which sparked an extensive search by Essex Police - were of her large pet cat, Teddy Bear. A search for the very large animal seen in St Osyth, near Clacton-on-Sea, on Sunday was called off on Monday. Ginny Murphy said her ginger Maine Coon cat, the largest domestic breed, regularly wanders into the field where the animal was spotted. She said she believes Teddy Bear was mistaken for a lion by holidaymakers. 'Like to hunt' A search by police was triggered on Sunday evening when people staying at a caravan park reported sightings of a very large animal near Earl Hall Drive. Experts from Colchester Zoo and police firearms officers helped in the search. Police decided to call off the search after no trace of a big cat was found and they said the sightings were either of a large domestic cat or wildcat. Ms Murphy, of St Osyth, said: From the picture, he's identical - he's big, he's always out in the fields. Maine Coons like to hunt, and where he was is a particular area he likes to go. He's always coming back with birds. Her three-year-old pet is about 28in (70cm) in length. Gill and Steve Atkin, of Louth, Lincolnshire, photographed an animal in the field on Sunday afternoon. Mr Atkin had told police it was definitely a very large animal, and possibly a lion, definitely a large cat. He added: We witnessed it, I would say, for about 20 to 30 minutes cleaning itself and rolling about in the field. Speaking to the BBC on Tuesday, Mrs Atkin said: The Mirror [newspaper] has made a bit of a farce of it this morning, saying it was a cat called Tom, but no, I don't think it was a domestic cat. Whatever it was, it's definitely still out there. The first reported sighting was made by holidaymaker Bob Martin, who said he and his wife Denise saw a large cat and a lion was the first thing that came to mind. Cost of search We believe we saw a large cat looking at a tree... it just sat there looking at us, he said. Essex Police have not released any details of the cost of the search, but have said about 25 officers were called to where the animal was seen, including specialist firearms officers and experts from Colchester Zoo. Two police helicopters, one with thermal imaging equipment, were also used to try to detect any trace of an animal.\")\n",
    "print(ents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "  # Let's focus on names and anonymize\n",
    "\n",
    "def anonymize(text):\n",
    "    ents = pipe(text, ignore_labels=[\"O\", \"LOC\", \"ORG\"])\n",
    "    split_text = list(text)\n",
    "    for ent in ents:\n",
    "        split_text[ent['start']] = f\"[{ent['entity_group']}]\"\n",
    "        for i in range(ent['start'] + 1, ent['end']):\n",
    "            split_text[i] = \"\"\n",
    "\n",
    "    return \"\".join(split_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Un exempleado de la aeronáutica Boeing conocido por expresar su preocupación por los estándares de la producción de la empresa fue encontrado muerto en Estados Unidos. [PER] había trabajado para Boeing durante 32 años, hasta su jubilación en 2017. En los días previos a su muerte, había estado testificando en un juicio contra la empresa tras denunciar irregularidades. Boeing manifestó su tristeza por el fallecimiento de [PER]. El oficial forense del condado de Charleston le confirmó su muerte a la BBC este lunes. Dijo que el hombre de 62 años había muerto de una herida de bala autoinfligida el 9 de marzo y que la policía estaba investigando.\n"
     ]
    }
   ],
   "source": [
    "text = \"Un exempleado de la aeronáutica Boeing conocido por expresar su preocupación por los estándares de la producción de la empresa fue encontrado muerto en Estados Unidos. John Barnett había trabajado para Boeing durante 32 años, hasta su jubilación en 2017. En los días previos a su muerte, había estado testificando en un juicio contra la empresa tras denunciar irregularidades. Boeing manifestó su tristeza por el fallecimiento de Barnett. El oficial forense del condado de Charleston le confirmó su muerte a la BBC este lunes. Dijo que el hombre de 62 años había muerto de una herida de bala autoinfligida el 9 de marzo y que la policía estaba investigando.\"\n",
    "anonymized_text = anonymize(text)\n",
    "print(anonymized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        英王室は24日、英女王エリザベス2世の墓所を示す墓標の写真を公表した。新しく刻まれた墓標に...\n",
      "1        The director of public prosecutions is bringi...\n",
      "2        Four men have admitted causing disruption dur...\n",
      "3        Liam Treadwell's teeth helped to make him one...\n",
      "4        A woman has claimed sightings of a lion- whic...\n",
      "                              ...                        \n",
      "8757     A US police chief has apologised for an insen...\n",
      "8758     Pakistani activists are calling for a high-le...\n",
      "8759     Ukrainian President Volodymyr Zelensky has be...\n",
      "8760      Fear, anger and lots of uncertainty.  That's...\n",
      "8761     Hans Rosling, the Swedish professor who made ...\n",
      "Name: text, Length: 8762, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Now that we've checked all works, let's apply it to BBC data. \n",
    "\n",
    "articles = pd.read_csv('AnomisedDataSample.csv')\n",
    "print(articles[\"text\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>URL</th>\n",
       "      <th>JSON_CONTENT</th>\n",
       "      <th>text</th>\n",
       "      <th>anonymised_text</th>\n",
       "      <th>famous_persons</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>https://www.bbc.com/japanese/63024308.amp</td>\n",
       "      <td>\"{\\\"metadata\\\": {\\\"id\\\": \\\"urn:bbc:ares::asset...</td>\n",
       "      <td>英王室は24日、英女王エリザベス2世の墓所を示す墓標の写真を公表した。新しく刻まれた墓標に...</td>\n",
       "      <td>英王室は24日、英女王エリザベス2世の墓所を示す墓標の写真を公表した。新しく刻まれた墓標に...</td>\n",
       "      <td>{\"Queen Elizabeth II\": [\"Queen Elizabeth II, (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>https://www.bbc.com/news/uk-63030330</td>\n",
       "      <td>\"{\\\"metadata\\\": {\\\"id\\\": \\\"urn:bbc:ares::asset...</td>\n",
       "      <td>The director of public prosecutions is bringi...</td>\n",
       "      <td>The director of public prosecutions is bringi...</td>\n",
       "      <td>{\"Max Hill\": [\"Max Hill, (https://en.wikipedia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>https://www.bbc.com/news/uk-england-tyne-34585196</td>\n",
       "      <td>\"{\\\"metadata\\\": {\\\"id\\\": \\\"urn:bbc:ares::asset...</td>\n",
       "      <td>Four men have admitted causing disruption dur...</td>\n",
       "      <td>Four men have admitted causing disruption dur...</td>\n",
       "      <td>{\"Kyle Binks\": [\"PERSON\", null], \"Newton Aycli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>https://www.bbc.com/sport/horse-racing/38057367</td>\n",
       "      <td>\"{\\\"metadata\\\": {\\\"id\\\": \\\"urn:bbc:ares::asset...</td>\n",
       "      <td>Liam Treadwell's teeth helped to make him one...</td>\n",
       "      <td>Liam Treadwell, (https://en.wikipedia.org/wik...</td>\n",
       "      <td>{\"Clare Balding\": [\"Clare Balding, (https://en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>https://www.bbc.com/news/uk-england-essex-1939...</td>\n",
       "      <td>\"{\\\"metadata\\\": {\\\"id\\\": \\\"urn:bbc:ares::asset...</td>\n",
       "      <td>A woman has claimed sightings of a lion- whic...</td>\n",
       "      <td>A woman has claimed sightings of a lion- whic...</td>\n",
       "      <td>{\"Ginny Murphy\": [\"PERSON\", null], \"Steve Atki...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                                URL  \\\n",
       "0           0          https://www.bbc.com/japanese/63024308.amp   \n",
       "1           1               https://www.bbc.com/news/uk-63030330   \n",
       "2           2  https://www.bbc.com/news/uk-england-tyne-34585196   \n",
       "3           3    https://www.bbc.com/sport/horse-racing/38057367   \n",
       "4           4  https://www.bbc.com/news/uk-england-essex-1939...   \n",
       "\n",
       "                                        JSON_CONTENT  \\\n",
       "0  \"{\\\"metadata\\\": {\\\"id\\\": \\\"urn:bbc:ares::asset...   \n",
       "1  \"{\\\"metadata\\\": {\\\"id\\\": \\\"urn:bbc:ares::asset...   \n",
       "2  \"{\\\"metadata\\\": {\\\"id\\\": \\\"urn:bbc:ares::asset...   \n",
       "3  \"{\\\"metadata\\\": {\\\"id\\\": \\\"urn:bbc:ares::asset...   \n",
       "4  \"{\\\"metadata\\\": {\\\"id\\\": \\\"urn:bbc:ares::asset...   \n",
       "\n",
       "                                                text  \\\n",
       "0   英王室は24日、英女王エリザベス2世の墓所を示す墓標の写真を公表した。新しく刻まれた墓標に...   \n",
       "1   The director of public prosecutions is bringi...   \n",
       "2   Four men have admitted causing disruption dur...   \n",
       "3   Liam Treadwell's teeth helped to make him one...   \n",
       "4   A woman has claimed sightings of a lion- whic...   \n",
       "\n",
       "                                     anonymised_text  \\\n",
       "0   英王室は24日、英女王エリザベス2世の墓所を示す墓標の写真を公表した。新しく刻まれた墓標に...   \n",
       "1   The director of public prosecutions is bringi...   \n",
       "2   Four men have admitted causing disruption dur...   \n",
       "3   Liam Treadwell, (https://en.wikipedia.org/wik...   \n",
       "4   A woman has claimed sightings of a lion- whic...   \n",
       "\n",
       "                                      famous_persons  \n",
       "0  {\"Queen Elizabeth II\": [\"Queen Elizabeth II, (...  \n",
       "1  {\"Max Hill\": [\"Max Hill, (https://en.wikipedia...  \n",
       "2  {\"Kyle Binks\": [\"PERSON\", null], \"Newton Aycli...  \n",
       "3  {\"Clare Balding\": [\"Clare Balding, (https://en...  \n",
       "4  {\"Ginny Murphy\": [\"PERSON\", null], \"Steve Atki...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articlesAnon = articles[:100]\n",
    "articlesAnon.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/var/folders/g1/88nr974j1j17df5pghy6fzyh0000gn/T/ipykernel_29639/3615251180.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  articlesAnon.loc[cell[0], \"bert_anonymized_text\"] = anonymized_text\n",
      "100it [00:31,  3.17it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for row_index, cell in tqdm(articlesAnon.iterrows()):\n",
    "    anonymized_text = anonymize(cell[\"text\"])\n",
    "    articlesAnon.loc[cell[0], \"bert_anonymized_text\"] = anonymized_text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>URL</th>\n",
       "      <th>JSON_CONTENT</th>\n",
       "      <th>text</th>\n",
       "      <th>anonymised_text</th>\n",
       "      <th>famous_persons</th>\n",
       "      <th>bert_anonymized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>https://www.bbc.com/japanese/63024308.amp</td>\n",
       "      <td>\"{\\\"metadata\\\": {\\\"id\\\": \\\"urn:bbc:ares::asset...</td>\n",
       "      <td>英王室は24日、英女王エリザベス2世の墓所を示す墓標の写真を公表した。新しく刻まれた墓標に...</td>\n",
       "      <td>英王室は24日、英女王エリザベス2世の墓所を示す墓標の写真を公表した。新しく刻まれた墓標に...</td>\n",
       "      <td>{\"Queen Elizabeth II\": [\"Queen Elizabeth II, (...</td>\n",
       "      <td>英王室は24日、英女王[PER]の墓所を示す墓標の写真を公表した。新しく刻まれた墓標には、...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>https://www.bbc.com/news/uk-63030330</td>\n",
       "      <td>\"{\\\"metadata\\\": {\\\"id\\\": \\\"urn:bbc:ares::asset...</td>\n",
       "      <td>The director of public prosecutions is bringi...</td>\n",
       "      <td>The director of public prosecutions is bringi...</td>\n",
       "      <td>{\"Max Hill\": [\"Max Hill, (https://en.wikipedia...</td>\n",
       "      <td>The director of public prosecutions is bringi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>https://www.bbc.com/news/uk-england-tyne-34585196</td>\n",
       "      <td>\"{\\\"metadata\\\": {\\\"id\\\": \\\"urn:bbc:ares::asset...</td>\n",
       "      <td>Four men have admitted causing disruption dur...</td>\n",
       "      <td>Four men have admitted causing disruption dur...</td>\n",
       "      <td>{\"Kyle Binks\": [\"PERSON\", null], \"Newton Aycli...</td>\n",
       "      <td>Four men have admitted causing disruption dur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>https://www.bbc.com/sport/horse-racing/38057367</td>\n",
       "      <td>\"{\\\"metadata\\\": {\\\"id\\\": \\\"urn:bbc:ares::asset...</td>\n",
       "      <td>Liam Treadwell's teeth helped to make him one...</td>\n",
       "      <td>Liam Treadwell, (https://en.wikipedia.org/wik...</td>\n",
       "      <td>{\"Clare Balding\": [\"Clare Balding, (https://en...</td>\n",
       "      <td>[PER]'s teeth helped to make him one of the b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>https://www.bbc.com/news/uk-england-essex-1939...</td>\n",
       "      <td>\"{\\\"metadata\\\": {\\\"id\\\": \\\"urn:bbc:ares::asset...</td>\n",
       "      <td>A woman has claimed sightings of a lion- whic...</td>\n",
       "      <td>A woman has claimed sightings of a lion- whic...</td>\n",
       "      <td>{\"Ginny Murphy\": [\"PERSON\", null], \"Steve Atki...</td>\n",
       "      <td>A woman has claimed sightings of a lion- whic...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                                URL  \\\n",
       "0           0          https://www.bbc.com/japanese/63024308.amp   \n",
       "1           1               https://www.bbc.com/news/uk-63030330   \n",
       "2           2  https://www.bbc.com/news/uk-england-tyne-34585196   \n",
       "3           3    https://www.bbc.com/sport/horse-racing/38057367   \n",
       "4           4  https://www.bbc.com/news/uk-england-essex-1939...   \n",
       "\n",
       "                                        JSON_CONTENT  \\\n",
       "0  \"{\\\"metadata\\\": {\\\"id\\\": \\\"urn:bbc:ares::asset...   \n",
       "1  \"{\\\"metadata\\\": {\\\"id\\\": \\\"urn:bbc:ares::asset...   \n",
       "2  \"{\\\"metadata\\\": {\\\"id\\\": \\\"urn:bbc:ares::asset...   \n",
       "3  \"{\\\"metadata\\\": {\\\"id\\\": \\\"urn:bbc:ares::asset...   \n",
       "4  \"{\\\"metadata\\\": {\\\"id\\\": \\\"urn:bbc:ares::asset...   \n",
       "\n",
       "                                                text  \\\n",
       "0   英王室は24日、英女王エリザベス2世の墓所を示す墓標の写真を公表した。新しく刻まれた墓標に...   \n",
       "1   The director of public prosecutions is bringi...   \n",
       "2   Four men have admitted causing disruption dur...   \n",
       "3   Liam Treadwell's teeth helped to make him one...   \n",
       "4   A woman has claimed sightings of a lion- whic...   \n",
       "\n",
       "                                     anonymised_text  \\\n",
       "0   英王室は24日、英女王エリザベス2世の墓所を示す墓標の写真を公表した。新しく刻まれた墓標に...   \n",
       "1   The director of public prosecutions is bringi...   \n",
       "2   Four men have admitted causing disruption dur...   \n",
       "3   Liam Treadwell, (https://en.wikipedia.org/wik...   \n",
       "4   A woman has claimed sightings of a lion- whic...   \n",
       "\n",
       "                                      famous_persons  \\\n",
       "0  {\"Queen Elizabeth II\": [\"Queen Elizabeth II, (...   \n",
       "1  {\"Max Hill\": [\"Max Hill, (https://en.wikipedia...   \n",
       "2  {\"Kyle Binks\": [\"PERSON\", null], \"Newton Aycli...   \n",
       "3  {\"Clare Balding\": [\"Clare Balding, (https://en...   \n",
       "4  {\"Ginny Murphy\": [\"PERSON\", null], \"Steve Atki...   \n",
       "\n",
       "                                bert_anonymized_text  \n",
       "0   英王室は24日、英女王[PER]の墓所を示す墓標の写真を公表した。新しく刻まれた墓標には、...  \n",
       "1   The director of public prosecutions is bringi...  \n",
       "2   Four men have admitted causing disruption dur...  \n",
       "3   [PER]'s teeth helped to make him one of the b...  \n",
       "4   A woman has claimed sightings of a lion- whic...  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articlesAnon.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "articlesAnon.to_csv(\"100AnonymisedArticlesTwoModels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
